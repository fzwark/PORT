1 : [
    'WizardLM/WizardLM-13B-V1.2', 'claude-instant-v1', 'claude-v1', 'claude-v2', 'gpt-3.5-turbo-1106', 'gpt-4-1106-preview', 'meta/code-llama-instruct-34b-chat', 'meta/llama-2-70b-chat', 'mistralai/mistral-7b-chat', 'mistralai/mixtral-8x7b-chat', 'zero-one-ai/Yi-34B-Chat'
  ]

0 : [
    "aws-claude-3-5-sonnet-v1", "aws-titan-text-premier-v1", "openai-gpt-4o", "openai-gpt-4o-mini", "wxai-granite-3-2b-instruct-8k-max-tokens",
    "wxai-granite-3-8b-instruct-8k-max-tokens", "wxai-llama-3-1-70b-instruct", "wxai-llama-3-1-8b-instruct", "wxai-llama-3-2-1b-instruct", 
    "wxai-llama-3-2-3b-instruct", "wxai-llama-3-3-70b-instruct", "wxai-llama-3-405b-instruct", "wxai-mixtral-8x7b-instruct-v01"
]

2 : ['01-ai/Yi-34B-Chat', 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'Qwen/QwQ-32B-Preview', 'Qwen/Qwen2-72B-Instruct', 'Qwen/Qwen2.5-72B-Instruct', 
      'Qwen/Qwen2.5-7B-Instruct', 'alpindale/WizardLM-2-8x22B', 'deepseek-ai/deepseek-llm-67b-chat', 'google/gemma-2-27b-it', 'google/gemma-2-9b-it', 
      'google/gemma-2b-it', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'mistralai/Mistral-7B-Instruct-v0.1', 
      'mistralai/Mistral-7B-Instruct-v0.2', 'mistralai/Mistral-7B-Instruct-v0.3', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF']

RAW_MODELS : [
          'open-llm-leaderboard/NousResearch__Nous-Hermes-2-Mixtral-8x7B-DPO-details',
          'open-llm-leaderboard/01-ai__Yi-34B-Chat-details',
          'open-llm-leaderboard/Qwen__QwQ-32B-Preview-details',
          'open-llm-leaderboard/Qwen__Qwen2-72B-Instruct-details',
          'open-llm-leaderboard/Qwen__Qwen2.5-7B-Instruct-details',
          'open-llm-leaderboard/Qwen__Qwen2.5-72B-Instruct-details',
          'open-llm-leaderboard/alpindale__WizardLM-2-8x22B-details',
          'open-llm-leaderboard/deepseek-ai__deepseek-llm-67b-chat-details',
          'open-llm-leaderboard/google__gemma-2-27b-it-details',
          'open-llm-leaderboard/google__gemma-2-9b-it-details',
          'open-llm-leaderboard/google__gemma-2b-it-details',
          'open-llm-leaderboard/meta-llama__Llama-2-13b-chat-hf-details',
          'open-llm-leaderboard/meta-llama__Meta-Llama-3.1-70B-Instruct-details',
          'open-llm-leaderboard/meta-llama__Meta-Llama-3.1-8B-Instruct-details',
          'open-llm-leaderboard/mistralai__Mistral-7B-Instruct-v0.1-details', 
          'open-llm-leaderboard/mistralai__Mistral-7B-Instruct-v0.2-details',
          'open-llm-leaderboard/mistralai__Mistral-7B-Instruct-v0.3-details',
          'open-llm-leaderboard/mistralai__Mixtral-8x22B-Instruct-v0.1-details',
          'open-llm-leaderboard/mistralai__Mixtral-8x7B-Instruct-v0.1-details',
          'open-llm-leaderboard/nvidia__Llama-3.1-Nemotron-70B-Instruct-HF-details',
          'open-llm-leaderboard/upstage__SOLAR-10.7B-Instruct-v1.0-details'
]


OPEN_BENCHMARKS : {'bbh':['leaderboard_bbh_boolean_expressions',
                     'leaderboard_bbh_causal_judgement',
                     'leaderboard_bbh_date_understanding',
                     'leaderboard_bbh_disambiguation_qa',
                     'leaderboard_bbh_formal_fallacies',
                     'leaderboard_bbh_geometric_shapes',
                     'leaderboard_bbh_hyperbaton',
                     'leaderboard_bbh_logical_deduction_five_objects',
                     'leaderboard_bbh_logical_deduction_seven_objects',
                     'leaderboard_bbh_logical_deduction_three_objects',
                     'leaderboard_bbh_movie_recommendation',
                     'leaderboard_bbh_navigate',
                     'leaderboard_bbh_object_counting',
                     'leaderboard_bbh_penguins_in_a_table',
                     'leaderboard_bbh_reasoning_about_colored_objects',
                     'leaderboard_bbh_ruin_names',
                     'leaderboard_bbh_salient_translation_error_detection',
                     'leaderboard_bbh_snarks',
                     'leaderboard_bbh_sports_understanding',
                     'leaderboard_bbh_temporal_sequences',
                     'leaderboard_bbh_tracking_shuffled_objects_five_objects',
                     'leaderboard_bbh_tracking_shuffled_objects_seven_objects',
                     'leaderboard_bbh_tracking_shuffled_objects_three_objects',
                     'leaderboard_bbh_web_of_lies'],
              'gpqa':['leaderboard_gpqa_diamond',
                     'leaderboard_gpqa_extended',
                     'leaderboard_gpqa_main'],
              'ifeval':['leaderboard_ifeval'],
              'math':['leaderboard_math_algebra_hard',
                     'leaderboard_math_counting_and_prob_hard',
                     'leaderboard_math_geometry_hard',
                     'leaderboard_math_intermediate_algebra_hard',
                     'leaderboard_math_num_theory_hard',
                     'leaderboard_math_prealgebra_hard',
                     'leaderboard_math_precalculus_hard'],
              'mmlu_pro':['leaderboard_mmlu_pro'],
              'musr':['leaderboard_musr_murder_mysteries',
                      'leaderboard_musr_object_placements',
                      'leaderboard_musr_team_allocation']}

